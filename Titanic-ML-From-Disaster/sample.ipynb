{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Kaggle Titanic - ML from Disaster\n",
    "\n",
    "The famous Kaggle Titanic competition.\n",
    "\n",
    "Steps to learn\n",
    "1. take Kaggle ML intro course\n",
    "2. take sci-kit learn course on datacamp\n",
    "3. get data on Jupyter\n",
    "4. clean the data (use fill values from pandas)\n",
    "5. begin training a model and generating predictions\n",
    "\n",
    "Important key concepts:\n",
    "- The training set is used to build the machine learning models. The ground truth is provided in this (whether they survived or not) so the model learns (aka supervised learning).\n",
    "- In ML, features are the input variables (the independent variables) used to make predictions. They represent specific properties or characteristics of a dataset. Features are important because they provide the information that the model learns from."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T22:39:35.830577Z",
     "start_time": "2025-02-16T22:39:35.817019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "train = pd.read_csv(\"train.csv\") # the data in this file will be used to train the data\n",
    "test = pd.read_csv(\"test.csv\") # the data in this file will be used to test our model which we built with the train data\n",
    "gender = pd.read_csv(\"gender_submission.csv\")\n",
    "\n",
    "train.head()"
   ],
   "id": "41e3d784bb166841",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Let's see what we have in our columns\n",
    "- __survival__    Survival\t0 = No, 1 = Yes\n",
    "- __pclass__\t  Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- __sex__\t  Sex\n",
    "- __Age__\t  Age in years\n",
    "- __sibsp__\t  # of siblings / spouses aboard the Titanic\n",
    "- __parch__\t  # of parents / children aboard the Titanic\n",
    "- __ticket__ \tTicket number\n",
    "- __fare__\t  Passenger fare\n",
    "- __cabin__  \tCabin number\n",
    "- __embarked__  \tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "Variable notes:\n",
    "- __pclass:__ A proxy for socio-economic status (SES)\n",
    "    1st = Upper\n",
    "    2nd = Middle\n",
    "    3rd = Lower\n",
    "- __age:__ Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "- __sibsp:__ The dataset defines family relations in this way...\n",
    "    Sibling = brother, sister, stepbrother, stepsister\n",
    "    Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "- __parch:__ The dataset defines family relations in this way...\n",
    "    Parent = mother, father\n",
    "    Child = daughter, son, stepdaughter, stepson\n",
    "    Some children travelled only with a nanny, therefore parch=0 for them.\n"
   ],
   "id": "f2fcbb60b27b423c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T22:39:35.856916Z",
     "start_time": "2025-02-16T22:39:35.852570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train.info()\n",
    "print()\n",
    "train.columns"
   ],
   "id": "d03929e5a2dfa37f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning and Feature Engineering\n",
    "\n",
    "Ok now let's identify what features are relevant in training our model. We will choose:\n",
    "- Pclass (Passenger class)\n",
    "- Sex\n",
    "- Fare\n",
    "\n",
    "In order for us to use Sex, we need to convert it to a numeric value. We will convert male to 0 and female to 1.\n"
   ],
   "id": "e2ead4c58a13da27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T22:39:35.881692Z",
     "start_time": "2025-02-16T22:39:35.877028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# let's use Pclass, Sex, and Fare. We will clean the data in train and test\n",
    "\n",
    "train[\"Sex\"] = train[\"Sex\"].map({\"male\": 0, \"female\": 1}) # converts the strings in train to binary numeric values\n",
    "test[\"Sex\"] = test[\"Sex\"].map({\"male\": 0, \"female\": 1})  # converts the strings in test to binary numeric values\n",
    "\n",
    "X = train[[\"Pclass\", \"Sex\", \"Fare\"]]\n",
    "X_test = test[[\"Pclass\", \"Sex\", \"Fare\"]]\n",
    "X.head()"
   ],
   "id": "5b1820d3ab0c1f0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Pclass  Sex     Fare\n",
       "0       3    0   7.2500\n",
       "1       1    1  71.2833\n",
       "2       3    1   7.9250\n",
       "3       1    1  53.1000\n",
       "4       3    0   8.0500"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we will assign our prediction target which by convention is usually y.",
   "id": "99633278c5951fe7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T22:52:27.187901Z",
     "start_time": "2025-02-16T22:52:27.183009Z"
    }
   },
   "cell_type": "code",
   "source": "y = train[\"Survived\"] # or y = train.Survived",
   "id": "5d470cfa33c2408a",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Steps to building a model\n",
    "1. __Define:__ What type of model will it be? What model is best for the problem I am trying to solve?\n",
    "2. __Fit:__ Capture patterns from the provided data. This is the heart of modeling\n",
    "3. __Predict:__ Run data through the model and predict\n",
    "4. __Evaluate:__ Evaluate the model and see how accurate it is in its prediction"
   ],
   "id": "b241ada8c4800378"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T22:39:35.931847Z",
     "start_time": "2025-02-16T22:15:38.685945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# we will use a decision tree model for this\n",
    "\n",
    "# learns pattern in the data like the if tree we looked at.\n",
    "titanic_model = DecisionTreeRegressor(random_state=1) # random-state=1 fixes randomness (results are reproducable)\n",
    "titanic_model.fit(X, y) # X is the independent variable and y is the dependent variable\n",
    "\n",
    "titanic_model.predict(X)"
   ],
   "id": "dfe724a60a290140",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.        , 0.6       , 1.        , 0.12195122,\n",
       "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.12195122, 0.        , 0.5       ,\n",
       "       1.        , 0.        , 0.14285714, 0.        , 1.        ,\n",
       "       0.2       , 0.14285714, 1.        , 0.75      , 0.        ,\n",
       "       1.        , 0.1       , 0.        , 1.        , 0.02702703,\n",
       "       0.        , 1.        , 0.66666667, 0.125     , 0.        ,\n",
       "       0.2       , 0.15384615, 0.12195122, 0.        , 1.        ,\n",
       "       0.        , 0.66666667, 0.02702703, 1.        , 1.        ,\n",
       "       0.12195122, 0.        , 0.66666667, 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.85714286, 0.        ,\n",
       "       0.75      , 0.875     , 0.15384615, 1.        , 0.        ,\n",
       "       0.15384615, 1.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.875     , 0.        , 0.6       , 0.09090909,\n",
       "       0.125     , 0.        , 0.        , 0.        , 0.71428571,\n",
       "       0.        , 0.02702703, 0.12195122, 1.        , 1.        ,\n",
       "       0.        , 0.22222222, 1.        , 0.        , 0.875     ,\n",
       "       1.        , 0.        , 0.12195122, 1.        , 0.12195122,\n",
       "       0.12195122, 0.11111111, 0.        , 0.5       , 0.        ,\n",
       "       0.12195122, 0.        , 1.        , 1.        , 0.2       ,\n",
       "       0.        , 0.02702703, 0.        , 0.        , 0.38461538,\n",
       "       0.02702703, 1.        , 0.15384615, 0.02702703, 0.33333333,\n",
       "       0.2       , 0.2       , 0.12195122, 0.        , 0.        ,\n",
       "       0.38461538, 0.10526316, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12195122, 0.        , 0.85714286, 0.        ,\n",
       "       1.        , 0.10526316, 1.        , 1.        , 0.5       ,\n",
       "       0.02702703, 0.        , 0.        , 0.85714286, 0.14285714,\n",
       "       0.        , 1.        , 0.33333333, 0.        , 0.33333333,\n",
       "       0.33333333, 0.66666667, 1.        , 0.        , 0.        ,\n",
       "       0.5       , 0.33333333, 0.        , 0.2       , 0.14285714,\n",
       "       0.        , 1.        , 0.12195122, 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.12195122, 0.09090909, 0.        ,\n",
       "       0.        , 1.        , 0.15384615, 0.09090909, 0.        ,\n",
       "       0.5       , 1.        , 0.        , 0.        , 0.71428571,\n",
       "       0.        , 0.        , 1.        , 0.38461538, 0.        ,\n",
       "       0.11111111, 0.        , 0.        , 0.14285714, 0.25      ,\n",
       "       0.        , 0.        , 0.5       , 0.5       , 1.        ,\n",
       "       0.        , 0.75      , 0.5       , 0.        , 0.02702703,\n",
       "       0.85714286, 0.14285714, 0.5       , 0.2       , 1.        ,\n",
       "       1.        , 0.10526316, 0.        , 0.66666667, 0.85714286,\n",
       "       0.22222222, 0.        , 0.        , 0.1       , 0.12195122,\n",
       "       0.        , 0.        , 0.5       , 0.66666667, 0.5       ,\n",
       "       0.        , 0.66666667, 0.        , 0.14285714, 0.10526316,\n",
       "       1.        , 0.6       , 0.        , 1.        , 0.125     ,\n",
       "       0.12195122, 0.14285714, 0.12195122, 0.02702703, 0.5       ,\n",
       "       0.        , 0.125     , 0.        , 0.14285714, 0.        ,\n",
       "       1.        , 0.15384615, 0.        , 1.        , 0.125     ,\n",
       "       0.5       , 0.2       , 1.        , 0.125     , 0.        ,\n",
       "       0.2       , 0.75      , 0.125     , 0.        , 0.1       ,\n",
       "       0.5       , 0.33333333, 1.        , 1.        , 0.2       ,\n",
       "       0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "       0.33333333, 1.        , 1.        , 1.        , 0.85714286,\n",
       "       0.10526316, 0.5       , 0.        , 0.        , 0.66666667,\n",
       "       0.125     , 0.        , 0.15384615, 1.        , 1.        ,\n",
       "       0.5       , 0.25      , 1.        , 0.33333333, 0.66666667,\n",
       "       1.        , 0.66666667, 0.        , 0.        , 1.        ,\n",
       "       0.10526316, 0.11111111, 0.22222222, 0.12195122, 0.        ,\n",
       "       0.09090909, 0.22222222, 0.02702703, 0.14285714, 0.66666667,\n",
       "       1.        , 1.        , 0.        , 0.        , 0.02702703,\n",
       "       0.        , 0.15384615, 0.33333333, 0.8       , 1.        ,\n",
       "       0.66666667, 1.        , 0.25      , 1.        , 0.12195122,\n",
       "       1.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "       1.        , 1.        , 0.85714286, 0.02702703, 0.        ,\n",
       "       0.5       , 0.85714286, 0.        , 1.        , 1.        ,\n",
       "       0.        , 0.02702703, 1.        , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.85714286, 1.        , 1.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.02702703, 0.        , 1.        , 0.12195122, 0.75      ,\n",
       "       0.2       , 1.        , 0.14285714, 0.14285714, 0.14285714,\n",
       "       0.85714286, 0.85714286, 0.66666667, 1.        , 0.09090909,\n",
       "       0.        , 0.        , 0.15384615, 0.        , 0.1       ,\n",
       "       0.22222222, 1.        , 0.85714286, 1.        , 1.        ,\n",
       "       0.        , 0.        , 0.2       , 0.        , 0.        ,\n",
       "       0.        , 1.        , 1.        , 0.66666667, 1.        ,\n",
       "       1.        , 0.        , 0.12195122, 0.        , 0.        ,\n",
       "       1.        , 1.        , 0.        , 0.        , 0.15384615,\n",
       "       1.        , 1.        , 0.38461538, 1.        , 0.02702703,\n",
       "       0.        , 0.        , 0.85714286, 0.        , 1.        ,\n",
       "       1.        , 0.33333333, 0.38461538, 1.        , 1.        ,\n",
       "       0.33333333, 0.5       , 0.2       , 0.125     , 1.        ,\n",
       "       0.38461538, 0.12195122, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10526316, 1.        , 0.15384615, 0.        ,\n",
       "       0.02702703, 0.        , 1.        , 0.        , 0.38461538,\n",
       "       0.        , 1.        , 0.85714286, 0.14285714, 0.33333333,\n",
       "       0.02702703, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.85714286, 0.85714286, 0.10526316, 0.12195122,\n",
       "       0.5       , 0.66666667, 0.85714286, 0.        , 0.        ,\n",
       "       1.        , 0.        , 1.        , 0.        , 0.125     ,\n",
       "       1.        , 0.22222222, 0.15384615, 0.85714286, 1.        ,\n",
       "       1.        , 1.        , 0.5       , 1.        , 0.8       ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.12195122,\n",
       "       0.02702703, 0.5       , 1.        , 0.875     , 0.10526316,\n",
       "       0.5       , 0.12195122, 0.        , 0.14285714, 0.12195122,\n",
       "       0.        , 0.        , 0.5       , 0.        , 1.        ,\n",
       "       0.        , 0.09090909, 1.        , 1.        , 0.        ,\n",
       "       0.2       , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.12195122, 0.5       , 1.        ,\n",
       "       0.        , 1.        , 0.33333333, 0.12195122, 1.        ,\n",
       "       0.        , 0.        , 0.8       , 0.        , 0.12195122,\n",
       "       0.        , 1.        , 0.        , 0.33333333, 0.33333333,\n",
       "       0.09090909, 0.66666667, 0.        , 0.5       , 1.        ,\n",
       "       0.        , 0.85714286, 0.5       , 0.        , 0.71428571,\n",
       "       0.10526316, 0.12195122, 1.        , 1.        , 0.        ,\n",
       "       0.        , 0.875     , 0.        , 0.85714286, 0.02702703,\n",
       "       1.        , 0.02702703, 0.1       , 1.        , 0.15384615,\n",
       "       0.10526316, 0.875     , 0.        , 0.38461538, 0.        ,\n",
       "       0.85714286, 0.15384615, 0.15384615, 1.        , 0.        ,\n",
       "       1.        , 0.5       , 1.        , 0.        , 1.        ,\n",
       "       1.        , 0.        , 0.        , 0.2       , 0.        ,\n",
       "       0.        , 0.85714286, 1.        , 0.5       , 0.5       ,\n",
       "       0.5       , 0.2       , 0.        , 0.1       , 0.33333333,\n",
       "       0.5       , 1.        , 0.        , 1.        , 1.        ,\n",
       "       0.10526316, 0.02702703, 0.        , 0.12195122, 0.        ,\n",
       "       0.        , 0.02702703, 0.        , 0.15384615, 0.11111111,\n",
       "       0.125     , 1.        , 1.        , 0.66666667, 0.12195122,\n",
       "       0.        , 0.85714286, 1.        , 0.        , 0.38461538,\n",
       "       1.        , 1.        , 0.2       , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.33333333, 0.12195122, 0.12195122,\n",
       "       0.        , 1.        , 0.        , 0.66666667, 0.2       ,\n",
       "       0.        , 1.        , 0.25      , 0.1       , 1.        ,\n",
       "       1.        , 0.02702703, 0.        , 0.12195122, 0.5       ,\n",
       "       0.        , 0.02702703, 0.8       , 1.        , 1.        ,\n",
       "       0.        , 0.        , 0.75      , 0.10526316, 0.12195122,\n",
       "       1.        , 0.        , 0.66666667, 1.        , 0.125     ,\n",
       "       0.        , 1.        , 1.        , 0.11111111, 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.02702703, 0.        ,\n",
       "       0.75      , 0.        , 0.8       , 0.        , 0.        ,\n",
       "       0.85714286, 0.38461538, 0.        , 0.        , 0.        ,\n",
       "       0.11111111, 1.        , 0.        , 0.71428571, 1.        ,\n",
       "       1.        , 0.02702703, 0.75      , 0.        , 0.5       ,\n",
       "       0.02702703, 1.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 0.02702703, 0.75      , 0.14285714, 0.        ,\n",
       "       1.        , 0.1       , 0.        , 0.        , 0.38461538,\n",
       "       0.        , 0.14285714, 0.15384615, 0.12195122, 1.        ,\n",
       "       1.        , 0.2       , 0.125     , 0.14285714, 0.        ,\n",
       "       0.15384615, 0.12195122, 1.        , 0.        , 1.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.5       ,\n",
       "       0.        , 0.        , 0.        , 0.33333333, 1.        ,\n",
       "       1.        , 1.        , 0.71428571, 0.1       , 0.5       ,\n",
       "       0.        , 0.12195122, 1.        , 0.5       , 0.        ,\n",
       "       1.        , 1.        , 0.2       , 0.        , 0.11111111,\n",
       "       0.2       , 1.        , 1.        , 0.33333333, 1.        ,\n",
       "       1.        , 0.5       , 0.2       , 0.        , 0.14285714,\n",
       "       0.        , 1.        , 0.875     , 0.        , 0.15384615,\n",
       "       1.        , 0.        , 0.14285714, 0.14285714, 0.33333333,\n",
       "       0.09090909, 0.66666667, 1.        , 0.2       , 0.6       ,\n",
       "       1.        , 0.5       , 0.        , 0.14285714, 0.14285714,\n",
       "       0.        , 0.        , 1.        , 0.02702703, 0.02702703,\n",
       "       0.75      , 0.        , 1.        , 0.        , 0.38461538,\n",
       "       0.        , 0.        , 0.85714286, 0.33333333, 0.10526316,\n",
       "       1.        , 1.        , 0.22222222, 0.02702703, 1.        ,\n",
       "       1.        , 0.33333333, 0.        , 0.12195122, 1.        ,\n",
       "       0.        , 0.        , 0.15384615, 1.        , 0.15384615,\n",
       "       1.        , 0.        , 0.66666667, 0.        , 0.        ,\n",
       "       0.22222222, 0.11111111, 0.875     , 0.1       , 1.        ,\n",
       "       0.10526316, 0.10526316, 1.        , 0.        , 1.        ,\n",
       "       1.        , 1.        , 0.75      , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.5       , 0.33333333,\n",
       "       0.10526316, 0.2       , 0.        , 0.        , 0.02702703,\n",
       "       0.14285714, 1.        , 1.        , 0.15384615, 0.33333333,\n",
       "       0.14285714, 1.        , 1.        , 1.        , 0.5       ,\n",
       "       0.15384615, 0.        , 0.33333333, 0.14285714, 1.        ,\n",
       "       0.        , 0.        , 0.125     , 0.        , 0.12195122,\n",
       "       0.        , 0.6       , 0.5       , 0.        , 0.        ,\n",
       "       1.        , 0.09090909, 0.        , 1.        , 0.        ,\n",
       "       0.        , 0.71428571, 0.5       , 0.10526316, 1.        ,\n",
       "       0.2       , 1.        , 0.15384615, 0.11111111, 0.        ,\n",
       "       1.        , 0.09090909, 0.12195122, 0.71428571, 0.33333333,\n",
       "       0.38461538, 0.125     , 1.        , 0.        , 0.09090909,\n",
       "       0.        , 0.        , 0.02702703, 0.        , 1.        ,\n",
       "       0.        , 0.15384615, 0.33333333, 1.        , 0.85714286,\n",
       "       1.        , 1.        , 0.5       , 1.        , 0.15384615,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.14285714,\n",
       "       0.85714286, 1.        , 0.        , 0.22222222, 1.        ,\n",
       "       0.02702703, 1.        , 0.        , 0.        , 1.        ,\n",
       "       1.        , 0.        , 0.02702703, 0.02702703, 1.        ,\n",
       "       0.85714286, 0.02702703, 0.        , 0.125     , 0.        ,\n",
       "       0.        , 0.14285714, 1.        , 0.        , 0.75      ,\n",
       "       0.10526316])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Predictions\n",
    "We now have probabilities for each passenger of survival on the Titanic. The closer the number is to 1, the more likely they are to survive. Looking up online, the percentage of people who died on the Titanic was roughly 63%. With the data our model used to train, it predicted 61% of the people had a greater than 50% chance of dying (550/891), pretty much accurate with real life."
   ],
   "id": "a2a9d0ac3f37b02a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T22:39:35.936513Z",
     "start_time": "2025-02-16T22:15:44.077646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_died = 0\n",
    "for x in (titanic_model.predict(X)):\n",
    "    if x < 0.5:\n",
    "        num_died += 1\n",
    "\n",
    "print(num_died)"
   ],
   "id": "270c2404898de53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "Now we evaluate the model. We need to use our test data for this. If we use our regular training data, we will get innacurate results when we actually deploy the model in a real scenario. We can split data using from sklearn.model_select import train_test_split, however, we already have test data so we will do the following:"
   ],
   "id": "247de8881867cb06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T22:39:35.937468Z",
     "start_time": "2025-02-16T22:39:23.512855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# in this scenario, we just predict and generate a file to submit to Kaggle. our current prediction generates 78% accuracy. not bad\n",
    "\n",
    "prediction = titanic_model.predict(X_test)\n",
    "print(prediction)\n",
    "submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": prediction.astype(int)})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ],
   "id": "878c65e8ed7d8f14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         0.125      0.09090909 1.         0.\n",
      " 0.         1.         1.         0.         0.02702703 0.\n",
      " 1.         0.2        1.         1.         0.         0.1\n",
      " 0.6        1.         0.         0.         1.         0.\n",
      " 1.         0.         1.         0.1        0.8        0.\n",
      " 0.2        0.         1.         0.         1.         0.15384615\n",
      " 0.         0.         0.22222222 0.71428571 1.         0.5\n",
      " 0.11111111 0.85714286 1.         0.38461538 0.33333333 0.10526316\n",
      " 1.         1.         0.         0.         1.         1.\n",
      " 1.         0.         0.02702703 0.         0.         1.\n",
      " 0.02702703 0.         0.10526316 1.         0.         0.66666667\n",
      " 1.         0.         0.         1.         0.66666667 0.02702703\n",
      " 0.6        0.         1.         0.         0.12195122 1.\n",
      " 0.14285714 0.66666667 1.         0.         0.         0.02702703\n",
      " 0.125      0.         1.         0.         0.66666667 1.\n",
      " 1.         0.15384615 1.         0.12195122 0.         0.33333333\n",
      " 1.         0.38461538 0.5        0.12195122 1.         0.2\n",
      " 0.10526316 0.15384615 0.         0.         0.         0.10526316\n",
      " 0.         0.14285714 0.         0.33333333 1.         1.\n",
      " 1.         0.         0.         1.         1.         0.85714286\n",
      " 1.         0.10526316 1.         0.         0.10526316 0.66666667\n",
      " 0.33333333 1.         0.14285714 0.12195122 0.12195122 0.\n",
      " 0.         0.         0.02702703 0.11111111 0.1        0.14285714\n",
      " 0.         0.         0.         0.33333333 0.         0.2\n",
      " 0.5        0.         0.         0.12195122 0.5        0.2\n",
      " 1.         0.02702703 0.12195122 1.         0.5        0.\n",
      " 1.         0.5        0.5        1.         1.         1.\n",
      " 1.         0.5        0.14285714 1.         0.         0.\n",
      " 1.         0.         0.         0.1        1.         0.15384615\n",
      " 0.5        1.         1.         1.         1.         1.\n",
      " 0.14285714 0.         1.         0.10526316 1.         1.\n",
      " 0.66666667 0.12195122 0.         0.14285714 0.2        0.\n",
      " 0.         0.         0.         0.11111111 1.         0.33333333\n",
      " 0.125      0.         0.75       0.         0.         0.85714286\n",
      " 0.125      0.         0.66666667 0.125      1.         0.02702703\n",
      " 0.         0.         0.         0.85714286 0.33333333 0.\n",
      " 1.         0.         1.         0.12195122 1.         0.12195122\n",
      " 0.875      0.33333333 1.         0.33333333 0.33333333 0.66666667\n",
      " 0.         0.14285714 0.         1.         0.         0.\n",
      " 0.         0.11111111 1.         0.1        0.85714286 1.\n",
      " 1.         1.         1.         0.         0.         0.\n",
      " 0.66666667 0.         0.85714286 0.2        1.         0.38461538\n",
      " 0.         0.         0.22222222 0.         0.10526316 0.12195122\n",
      " 0.85714286 0.15384615 0.         0.11111111 1.         1.\n",
      " 0.         0.02702703 0.         0.         0.         0.09090909\n",
      " 1.         0.10526316 1.         0.75       0.1        0.85714286\n",
      " 0.125      0.2        0.         0.125      0.         1.\n",
      " 0.66666667 0.33333333 0.         0.         0.         0.\n",
      " 0.15384615 0.12195122 0.         0.         0.15384615 1.\n",
      " 0.22222222 0.02702703 1.         0.         0.         0.11111111\n",
      " 0.15384615 0.         0.         0.09090909 0.66666667 1.\n",
      " 1.         0.         1.         0.         0.09090909 0.1\n",
      " 0.         0.66666667 1.         1.         1.         0.125\n",
      " 0.11111111 0.         0.15384615 0.15384615 0.14285714 0.5\n",
      " 1.         0.         1.         0.33333333 0.2        0.14285714\n",
      " 1.         0.33333333 0.1        1.         0.02702703 0.\n",
      " 0.14285714 0.15384615 0.         0.15384615 0.125      0.\n",
      " 0.         1.         0.         1.         0.14285714 1.\n",
      " 0.         0.66666667 1.         0.125      0.         0.\n",
      " 1.         0.         1.         0.         0.10526316 0.75\n",
      " 0.         1.         0.66666667 0.09090909 1.         0.\n",
      " 0.         0.         1.         1.         0.         1.\n",
      " 0.         0.14285714 1.         1.         0.         0.\n",
      " 0.         0.5        0.10526316 0.         0.         0.66666667\n",
      " 0.         1.         0.15384615 0.14285714 0.10526316 0.\n",
      " 1.         1.         0.         0.125      0.         1.\n",
      " 0.         1.         0.15384615 0.         1.         0.\n",
      " 1.         0.         0.         1.         0.125      0.\n",
      " 1.         1.         0.66666667 1.         0.33333333 0.12195122\n",
      " 1.         0.         0.12195122 0.        ]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluating the Model using test_train_split\n",
    "Here we will import test_train_split and split our train data to use it to see how accurate our model is using mean absolute error (MAE)"
   ],
   "id": "3c30c4d2f3584ce1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T23:03:31.754067Z",
     "start_time": "2025-02-16T23:03:31.745683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, y, random_state=1) # remember X is our original features we chose and y is the boolean (died or not)\n",
    "\n",
    "titanic_model2 = DecisionTreeRegressor(random_state=1) # let's create a new model and fit\n",
    "titanic_model2.fit(train_X, train_Y)\n",
    "\n",
    "prediction = titanic_model2.predict(test_X) # predicts using our split data (untrained)\n",
    "mean_absolute_error(test_Y, prediction) # the order of the arguments does not matter\n"
   ],
   "id": "c2a55bcc9e023945",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20087712486815626"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
